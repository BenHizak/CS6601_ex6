{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f18ed3d7",
   "metadata": {},
   "source": [
    "# Assignment 6: Hidden Markov Models\n",
    "\n",
    "## Submission\n",
    "All submissions will be via Gradescope. If you're completing this assignment in Jupyter Notebook, you must run the `notebook2script.py` file to export your work to a python file. To generate your submission file, run the command \n",
    "\n",
    "`python notebook2script.py submission`\n",
    "\n",
    "and your file will be created under the `submission` directory.\n",
    "\n",
    "Upload the resulting `submission.py` file to the Assignment 6 assignment on Gradescope for feedback.\n",
    "\n",
    "#### IMPORTANT: A total of 10 submissions is allowed for this assignment. Please use your submissions carefully and do not submit until you have thoroughly tested your code locally.\n",
    "\n",
    "#### If you're at 9 submissions, use your tenth and last submission wisely. The submission marked as â€˜Activeâ€™ in Gradescope will be the submission counted towards your grade. \n",
    "\n",
    "Please also submit your submission.py to Canvas as backup.\n",
    "\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "The goal of this assignment is to demonstrate the power of probabilistic models. You will build a word recognizer for American Sign Language (ASL) video sequences. In particular, this project employs hidden Markov models (HMM's) to analyze a series of measurements taken from videos of isolated American Sign Language (ASL) signs collected for research. (see the [Isolated Sign Language Recognition Corpus](https://www.kaggle.com/competitions/asl-signs/)).\n",
    "\n",
    "In each video, an ASL signer signs a meaningful sentence. In a typical ASL recognition system, you observe the XY coordinates of the speaker's left hand, right hand, and nose for every frame. The following diagram shows how the positions of the left hand (Red), right hand (Blue), and nose (Green) change over time. Saturation of colors represents time elapsed:\n",
    "\n",
    "![](demo/hands_nose_position.png) \n",
    "\n",
    "In this assignment, for the sake of simplicity, you will only use the Y-coordinates of the right hand and the right thumb to construct your HMM. In Part 1 you will build a one dimensional model, recognizing words based only on a series of right-hand Y coordinates; in Part 2 you will go multidimensional and utilize both the right hand and the right thumb features. At this point, you will have two observed coordinates at each time step (frame) representing right hand & right thumb Y positions.\n",
    "\n",
    "The words you will be recognizing are \"ALLIGATOR\", \"NUTS\", and \"SLEEP\". These individual signs can be seen in the sign phrases from our dataset:\n",
    "\n",
    "![](demo/alligator-singlesign-00000015.gif) \n",
    "\n",
    "### ALLIGATOR \n",
    "\n",
    "![](demo/nuts-singlesign-00000016.gif) \n",
    "\n",
    "### NUTS \n",
    "\n",
    "![](demo/sleep-singlesign-00000001.gif) \n",
    "\n",
    "### SLEEP "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8570e0",
   "metadata": {},
   "source": [
    "### Part 1a: Encoding the HMM\n",
    "### _[CS6601: 15 Points]_ _[CS3600: 25 Points]_\n",
    "\n",
    "Follow the method taught on Udacity **Lecture 8: 29. HMM Training** to determine following values for each word:\n",
    "1. the transition probabilities of each state\n",
    "2. the mean & standard deviation of emission Gaussian distribution of each state\n",
    "\n",
    "Use the training samples from the table below. Provide the transition, prior, and emission probabilities parameters for all three words with **accuracy to 3 decimal digits**.\n",
    "\n",
    "Round the values to 3 decimal places thoughout entire assignment:\n",
    "- 0.1 stays 0.1 or 0.100\n",
    "- 0.1234 rounds to 0.123\n",
    "- 0.2345 rounds to 0.235\n",
    "- 0.3456 rounds to 0.346\n",
    "- 0.0123 rounds to 0.012\n",
    "- 0.0125 rounds to 0.013\n",
    "\n",
    "#### When calculating the self transition probability (e.g. P(A2 -> A2)), you should calculate it as 1 - exit transition probability (e.g. 1 - P(A2->A3))\n",
    "\n",
    "Those values can be hardcoded in your program. Don't use round() from python.\n",
    "\n",
    "Word | Frames | Observed sequence | Initial State1 | Initial State2 | Initial State3\n",
    "--- | --- | --- | --- | --- | --- \n",
    "ALLIGATOR | 17 | 31, 28, 28, 37, 68, 49, 64, 66, 22, 17, 53, 73, 81, 78, 48, 49, 47 | 31, 28, 28, 37, 68, 49 | 64, 66, 22, 17, 53, 73 | 81, 78, 48, 49, 47\n",
    "ALLIGATOR | 10 | 25, 62, 75, 80, 75, 36, 74, 33, 27, 34 | 25, 62, 75, 80 | 75, 36, 74, 33 | 27, 34\n",
    "ALLIGATOR | 16 | -4, 69, 59, 45, 62, 22, 17, 28, 12, 14, 24, 32, 39, 61, 35, 32 | -4, 69, 59, 45, 62, 22 | 17, 28, 12, 14, 24, 32 | 39, 61, 35, 32\n",
    "NUTS | 11 | 45, 68, 62, 75, 61, 44, 73, 72, 71, 75, 55 | 45, 68, 62, 75 | 61, 44, 73, 72 | 71, 75, 55\n",
    "NUTS | 18 | 33, 33, 32, 32, 34, 38, 43, 41, 35, 36, 36, 37, 38, 38, 39, 40, 38, 38 | 33, 33, 32, 32, 34, 38 | 43, 41, 35, 36, 36, 37 | 38, 38, 39, 40, 38, 38\n",
    "NUTS | 19 | 33, 31, 29, 28, 25, 24, 25, 28, 28, 38, 37, 40, 37, 36, 36, 38, 44, 48, 48 | 33, 31, 29, 28, 25, 24, 25 | 28, 28, 38, 37, 40, 37, 36 | 36, 38, 44, 48, 48\n",
    "SLEEP | 8 | 37, 35, 41, 39, 41, 38, 38, 38 | 37, 35, 41 | 39, 41, 38 | 38, 38\n",
    "SLEEP | 12 | 22, 17, 18, 35, 33, 36, 42, 36, 41, 41, 37, 38 | 22, 17, 18, 35 | 33, 36, 42, 36 | 41, 41, 37, 38\n",
    "SLEEP | 13 | 38, 37, 35, 32, 35, 13, 36, 41, 41, 31, 32, 34, 34 | 38, 37, 35, 32, 35 | 13, 36, 41, 41, 31 | 32, 34, 34\n",
    "\n",
    "As shown in the diagram below, each one of the three words (ALLIGATOR, NUTS, and SLEEP) has exactly **THREE hidden states** in its HMM. All words have equal probability of occuring. Modify the prior accordingly. All words must start from State 1 and can only transit to the next state or stay in the current one as shown below:\n",
    "\n",
    "<img src=\"part_1_a_probs.png\">\n",
    "\n",
    "### _Training sequences need to have 3 hidden states no matter what!_\n",
    "If you follow the procedure on the Udacity lecture video, you might encounter a situation where a hidden state is **_squeezed_** out by an adjacent state. In that situation, always keep at least one observation for that hidden state.\n",
    "\n",
    "Example:\n",
    "Assume you've reached a stage where the following is true: \n",
    "- State 1 has mean=53 & std=6\n",
    "- State 2 has mean=37 & std=9\n",
    "- State 3 has mean=70 & std=8\n",
    "\n",
    "The next training sample has the following observed sequence:\n",
    "\n",
    "`45 45 34 | 30 30 25 36 52 | 62 69 74` \n",
    "\n",
    "and you are trying to adjust the location of state boundary between State 1 & 2. You first move it 1 step to the left since 34 is closer to State 2, and then you realize that 45 is still closer to State 2. If you follow the same routine, you will end up with no obvervation for State 1. In order to prevent this from happening, you have to stop at the last \"45\" and as a result leave the boundary as \n",
    "\n",
    "`45 | 45 34 30 30 25 36 52 | 62 69 74`\n",
    "\n",
    "Now you meet the '3 hidden states per sample' requirement.\n",
    "\n",
    "### Some hints/guidelines for training:\n",
    "#### 1. How should we compare if an observation if closer to one state or another?\n",
    "Check how many standard deviations away is the observation from the mean for each state. \n",
    "Example: Say 46 is the rightmost observation in State 1. If we denote the mean and std of State i as Î¼i,Ïƒi, then should we be comparing \n",
    "|46âˆ’Î¼1| / Ïƒ1 vs |46âˆ’Î¼2| / Ïƒ2\n",
    "\n",
    "#### 2. For HMM training, which side of the boundary should we check first while assigning observed sequence values to states?\n",
    "After computing the mean and std for each state, adjust the boundary between the states. Always start from the 1st element at the LEFT side of the boundary. If the LEFT element is closer to the next state, then move the boundary leftward. If the LEFT element should stay at the current state, then check the RIGHT element. This is just done to make sure that everyone gets the same results in the context of the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aaae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hmm_submission_test as tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114b6020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a46597",
   "metadata": {},
   "source": [
    "Load my Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e27d888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def my_data():\n",
    "a1 = np.array([31, 28, 28, 37, 68, 49, 64, 66, 22, 17, 53, 73, 81, 78, 48, 49, 47],dtype=np.int8)\n",
    "a2 = np.array([25, 62, 75, 80, 75, 36, 74, 33, 27, 34],dtype=np.int8)\n",
    "a3 = np.array([-4, 69, 59, 45, 62, 22, 17, 28, 12, 14, 24, 32, 39, 61, 35, 32],dtype=np.int8)\n",
    "n1 = np.array([45, 68, 62, 75, 61, 44, 73, 72, 71, 75, 55],dtype=np.int8)\n",
    "n2 = np.array([33, 33, 32, 32, 34, 38, 43, 41, 35, 36, 36, 37, 38, 38, 39, 40, 38, 38],dtype=np.int8)\n",
    "n3 = np.array([33, 31, 29, 28, 25, 24, 25, 28, 28, 38, 37, 40, 37, 36, 36, 38, 44, 48, 48],dtype=np.int8)\n",
    "s1 = np.array([37, 35, 41, 39, 41, 38, 38, 38],dtype=np.int8)\n",
    "s2 = np.array([22, 17, 18, 35, 33, 36, 42, 36, 41, 41, 37, 38],dtype=np.int8)\n",
    "s3 = np.array([38, 37, 35, 32, 35, 13, 36, 41, 41, 31, 32, 34, 34],dtype=np.int8)\n",
    "a_combined = np.array((a1,a2,a3), dtype=object)\n",
    "n_combined = np.array((n1,n2,n3), dtype=object)\n",
    "s_combined = np.array((s1,s2,s3), dtype=object)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b349d0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_partitions(sample,p1,p2):\n",
    "    # print (f\"ğŸ˜€sample = {sample}\")\n",
    "    return  f\"{sample[:p1]} ğŸŸ¢ {sample[p1:p2]} ğŸŸ¢ {sample[p2:]}\"\n",
    "def total_stddev(sample,p1,p2):\n",
    "    assert 0 < p1 < p2 < len(sample), f\"total_stddev(): partitions must start strictly inside the array. Condition fail (0 < {p1} < {p2} < {len(sample)})\"\n",
    "    return np.std(sample[:p1]) + np.std(sample[p1:p2]) + np.std(sample[p2:])\n",
    "\n",
    "def improve_partition(sample: np.ndarray, p1:int,p2:int, mu_left:float,mu_middle:float,\n",
    "                      mu_right:float,stddev_left:float,\n",
    "                      stddev_middle:float,stddev_right:float):\n",
    "    p1_old, p2_old = p1, p2\n",
    "\n",
    "    assert p1 is not None and p2 is not None, \"partitions should be valid\"\n",
    "\n",
    "    sample_length = sample.shape[0]\n",
    "    print (f\"sample: {sample}, partitions = ({p1},{p2}), len = {sample_length}\")\n",
    "    assert 0 < p1 < p2 < sample_length, f\"improve_partition(): partitions must start strictly inside the array. Condition fail (0 < {p1} < {p2} < {sample_length})\"\n",
    "\n",
    "    # for k in range(20):\n",
    "    #     print (f\"improve_partition(): left iteration = {k}\")\n",
    "        # sample [p1] is the first element of the next group \n",
    "    p1_moved = False\n",
    "    #check if element to left of the border p1 wants to move right (by moving the barrier left)\n",
    "    while abs(sample[p1-1] - mu_left) / stddev_left > abs(sample[p1-1] - mu_middle)/stddev_middle  and  1 < p1:\n",
    "        print (\"   1st partition moves â¬…ï¸ \", show_partitions(sample,p1,p2), \\\n",
    "                f\" left_fit={round(abs(sample[p1-1] - mu_left) / stddev_left,3)},middle_fit={round(abs(sample[p1-1] - mu_middle)/stddev_middle,3)},\")\n",
    "        print(f\"   improvement= {total_stddev(sample,p1-1,p2)<total_stddev(sample,p1,p2)}\")\n",
    "        p1 -= 1\n",
    "        p1_moved = True\n",
    "        #check if element to right of the border p1 wants to move left (by moving the barrier right)\n",
    "    while  abs(sample[p1] - mu_left) / stddev_left < abs(sample[p1] - mu_middle)/stddev_middle   and p1 < p2-1 and not p1_moved :\n",
    "        print (\"   1st partition moves â¡ï¸ \", show_partitions(sample,p1,p2), \\\n",
    "                f\" left_fit={round(abs(sample[p1] - mu_left) / stddev_left ,3)},middle_fit={round(abs(sample[p1] - mu_middle)/stddev_middle,3)},\")\n",
    "        print(f\"   improvement= {total_stddev(sample,p1+1,p2)<total_stddev(sample,p1,p2)}\")\n",
    "        p1 += 1\n",
    "    # else:\n",
    "        # print (\"p1: ended without reaching end of loop ğŸ˜€\")\n",
    "            # break\n",
    "        # if k==19:\n",
    "        #     print (f\"p1: reached end of loop ğŸš©ğŸš©ğŸš©\")\n",
    "    # for k in range(20):\n",
    "    #     print (f\"improve_partition(): right iteration = {k}\")\n",
    "    p2_moved = False\n",
    "    while abs(sample[p2-1] - mu_middle)/stddev_middle > abs(sample[p2-1] - mu_right)/stddev_right and p1 < p2-1:\n",
    "        print (\"   2nd partition moves â¬…ï¸ \",  show_partitions(sample,p1,p2), \\\n",
    "                f\" middle_fit={round(abs(sample[p2-1] - mu_middle)/stddev_middle,3)},right_fit={round(abs(sample[p2-1] - mu_right)/stddev_right,3)},\")\n",
    "        print(f\"   improvement= {total_stddev(sample,p1,p2-1)<total_stddev(sample,p1,p2)}\")\n",
    "        p2 -= 1\n",
    "        p2_moved = True\n",
    "    #check if element to right of the border p2 wants to move left (by moving the barrier right)\n",
    "    while abs(sample[p2] - mu_middle)/stddev_middle  < abs(sample[p2] - mu_right)/stddev_right and  p2 <sample_length-1 and not p2_moved:\n",
    "        print (\"   2nd partition moves â¡ï¸ \",show_partitions(sample,p1,p2) , \\\n",
    "                f\" middle_fit={round(abs(sample[p2] - mu_middle)/stddev_middle,3)},right_fit={round(abs(sample[p2] - mu_right)/stddev_right ,3)},\")\n",
    "        print(f\"   improvement= {total_stddev(sample,p1,p2+1)<total_stddev(sample,p1,p2)}\")\n",
    "        p2 += 1\n",
    "    #check if element to left of the border p2 wants to move right (by moving the barrier left)\n",
    "    # else:\n",
    "    #     print (\"p2: ended without reaching end of loop ğŸ˜€\")\n",
    "        # break\n",
    "        # if k==19:\n",
    "        #     print (f\"p2: reached end of loop ğŸš©ğŸš©ğŸš©\")\n",
    "    assert 0 < p1 < p2 < sample_length, f\"improve_partition():  paritions must end strictly inside the array. Condition fail (0 < {p1} < {p2} < {sample_length})\"\n",
    "\n",
    "    partitions_moved = (p1_old == p1) and (p2_old == p2) #true if one of the paritions moved\n",
    "    return (p1, p2, partitions_moved)\n",
    "    \n",
    "\n",
    "def partition_word(word_samples,initial_partition):\n",
    "    partition = np.array(initial_partition,np.int8)\n",
    "    print (f\"partitions: \\n{partition}\",)\n",
    "    for k in range (100): #1000 is an arbitrary limit to make sure we don't get stuck in infinite loop\n",
    "        left_data = np.concatenate((word_samples[0][:partition[0,0]], \\\n",
    "                                    word_samples[1][:partition[1,0]], \\\n",
    "                                    word_samples[2][:partition[2,0]]))\n",
    "        middle_data = np.concatenate((word_samples[0][partition[0,0]:partition[0,1]], \\\n",
    "                                      word_samples[1][partition[1,0]:partition[1,1]], \\\n",
    "                                      word_samples[2][partition[2,0]:partition[2,1]]))\n",
    "        right_data = np.concatenate((word_samples[0][partition[0,1]:], \\\n",
    "                                     word_samples[1][partition[1,1]:], \\\n",
    "                                     word_samples[2][partition[2,1]:]))\n",
    "        \n",
    "        mu_left = np.mean(left_data)\n",
    "        mu_middle = np.mean(middle_data)\n",
    "        mu_right =  np.mean(right_data)\n",
    "        stddev_left =  np.std(left_data)\n",
    "        stddev_middle = np.std(middle_data)\n",
    "        stddev_right =  np.std(right_data)\n",
    "        partitions_old = partition.copy()\n",
    "        print (\"updated means, stddev ğŸ², iteration k={k}\")\n",
    "        for i in range (3):\n",
    "            print(f\"ğŸ¦• word i={i}\")\n",
    "            (partition[i,0], partition[i,1], partitions_unchanged) = improve_partition(sample=word_samples[i], \\\n",
    "                                                            p1=partition[i,0], p2=partition[i,1], \\\n",
    "                                                            mu_left=mu_left,mu_middle=mu_middle, \\\n",
    "                                                            mu_right=mu_right,stddev_left=stddev_left, \\\n",
    "                                                            stddev_middle=stddev_middle,stddev_right=stddev_right)\n",
    "        partitions_unchanged = np.array_equal(partitions_old, partition)\n",
    "        if partitions_unchanged:\n",
    "            print (f\"no partitions moved, breaking (iteration = {k})\")\n",
    "            break\n",
    "        else:\n",
    "            print (f\"partitions moved, continuing (iteration = {k})\")\n",
    "\n",
    "    assert left_data is not None   , \"partition_word(): something is wrong left_data\"\n",
    "    assert middle_data is not None , \"partition_word(): something is wrong middle_data\"\n",
    "    assert right_data is not None  , \"partition_word(): something is wrong right_data\"\n",
    "    print (\"done â­â­â­â­â­â­â­. Partition Follows:\")\n",
    "    print (partition)\n",
    "    # print (f\"left_data = {left_data}, middle_data = {middle_data}, right_data = {right_data}\")\n",
    "\n",
    "    left_data = np.concatenate((word_samples[0][:partition[0,0]], \\\n",
    "                            word_samples[1][:partition[1,0]], \\\n",
    "                            word_samples[2][:partition[2,0]]))\n",
    "    middle_data = np.concatenate((word_samples[0][partition[0,0]:partition[0,1]], \\\n",
    "                                word_samples[1][partition[1,0]:partition[1,1]], \\\n",
    "                                word_samples[2][partition[2,0]:partition[2,1]]))\n",
    "    right_data = np.concatenate((word_samples[0][partition[0,1]:], \\\n",
    "                                word_samples[1][partition[1,1]:], \\\n",
    "                                word_samples[2][partition[2,1]:]))\n",
    "\n",
    "    mu_left = np.mean(left_data)\n",
    "    mu_middle = np.mean(middle_data)\n",
    "    mu_right =  np.mean(right_data)\n",
    "    stddev_left =  np.std(left_data)\n",
    "    stddev_middle = np.std(middle_data)\n",
    "    stddev_right =  np.std(right_data)\n",
    "\n",
    "    print(f\"mu_left={mu_left} ,stddev_left={stddev_left}\\nmu_middle={mu_middle} ,stddev_middle={stddev_middle} \\n,mu_right={mu_right},stddev_right={stddev_right}  \")\n",
    "    print(f\"left frame count = {len(left_data)}, transition prob = {3.0/len(left_data)}, self = {1-3.0/len(left_data)}\")\n",
    "    print(f\"middle frame count = {len(middle_data)}, transition prob = {3.0/len(middle_data)}, self = {1-3.0/len(middle_data)}\")\n",
    "    print(f\"right frame count = {len(right_data)}, transition prob = {3.0/len(right_data)}, self = {1-3.0/len(right_data)}\")\n",
    "    return (left_data,middle_data,right_data)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd332de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_partition = [[6,12],[4,8],[6,12]]\n",
    "# left,middle,right = np.empty((1)),np.empty((1)),np.empty((1))\n",
    "left,middle,right = partition_word(a_combined,initial_partition=a_partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bc65db",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_partition = [[4,8],[6,12],[7,14]]\n",
    "\n",
    "left,middle,right = partition_word(n_combined,initial_partition=n_partition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321038fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_partition = [[3,6],[4,8],[5,10]]\n",
    "\n",
    "left,middle,right = partition_word(s_combined,initial_partition=s_partition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdc966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def part_1_a():\n",
    "    \"\"\"Provide probabilities for the word HMMs outlined below.\n",
    "    Word ALLIGATOR, NUTS, and SLEEP.\n",
    "    Review Udacity Lesson 8 - Video #29. HMM Training\n",
    "    Returns:\n",
    "        tuple() of\n",
    "        (prior probabilities for all states for word ALLIGATOR,\n",
    "         transition probabilities between states for word ALLIGATOR,\n",
    "         emission parameters tuple(mean, std) for all states for word ALLIGATOR,\n",
    "         prior probabilities for all states for word NUTS,\n",
    "         transition probabilities between states for word NUTS,\n",
    "         emission parameters tuple(mean, std) for all states for word NUTS,\n",
    "         prior probabilities for all states for word SLEEP,\n",
    "         transition probabilities between states for word SLEEP,\n",
    "         emission parameters tuple(mean, std) for all states for word SLEEP)\n",
    "        Sample Format (not complete):\n",
    "        (\n",
    "            {'A1': prob_of_starting_in_A1, 'A2': prob_of_starting_in_A2, ...},\n",
    "            {'A1': {'A1': prob_of_transition_from_A1_to_A1,\n",
    "                    'A2': prob_of_transition_from_A1_to_A2,\n",
    "                    'A3': prob_of_transition_from_A1_to_A3,\n",
    "                    'Aend': prob_of_transition_from_A1_to_Aend},\n",
    "             'A2': {...}, ...},\n",
    "            {'A1': tuple(mean_of_A1, standard_deviation_of_A1),\n",
    "             'A2': tuple(mean_of_A2, standard_deviation_of_A2), ...},\n",
    "            {'N1': prob_of_starting_in_N1, 'N2': prob_of_starting_in_N2, ...},\n",
    "            {'N1': {'N1': prob_of_transition_from_N1_to_N1,\n",
    "                    'N2': prob_of_transition_from_N1_to_N2,\n",
    "                    'N3': prob_of_transition_from_N1_to_N3,\n",
    "                    'Nend': prob_of_transition_from_N1_to_Nend},\n",
    "             'N2': {...}, ...}\n",
    "            {'N1': tuple(mean_of_N1, standard_deviation_of_N1),\n",
    "             'N2': tuple(mean_of_N2, standard_deviation_of_N2), ...},\n",
    "            {'S1': prob_of_starting_in_S1, 'S2': prob_of_starting_in_S2, ...},\n",
    "            {'S1': {'S1': prob_of_transition_from_S1_to_S1,\n",
    "                    'S2': prob_of_transition_from_S1_to_S2,\n",
    "                    'S3': prob_of_transition_from_S1_to_S3,\n",
    "                    'Send': prob_of_transition_from_S1_to_Send},\n",
    "             'S2': {...}, ...}\n",
    "            {'S1': tuple(mean_of_S1, standard_deviation_of_S1),\n",
    "             'S2': tuple(mean_of_S2, standard_deviation_of_S2), ...} \n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    \"\"\"Word ALLIGATOR\"\"\"\n",
    "    a_prior_probs = {\n",
    "        'A1': 0.333,\n",
    "        'A2': 0.,\n",
    "        'A3': 0.,\n",
    "        'Aend': 0.\n",
    "    }\n",
    "    a_transition_probs = {\n",
    "        'A1': {'A2': 0.167, 'A3': 0., 'A1': 0.833, 'Aend': 0.},\n",
    "        'A2': {'A1': 0., 'A2': 0.786, 'A3': 0.214, 'Aend': 0.},\n",
    "        'A3': {'A2': 0., 'A1': 0., 'A3': 0.727, 'Aend': 0.273},\n",
    "        'Aend': {'A2': 0., 'A3': 0., 'A1': 0., 'Aend': 1}\n",
    "    }\n",
    "    # Parameters for end state is not requiredÍó „‚Íï¸Íó „ŒÍó „Íï¸†Íï¸‹Íó „\n",
    "    a_emission_paras = {\n",
    "        'A1': (51.056, 21.986),\n",
    "        'A2': (28.357, 14.936),\n",
    "        'A3': (53.727, 16.707),\n",
    "        'Aend': (None, None)\n",
    "    }\n",
    "\n",
    "\n",
    "#     mu_left=38.08108108108108 ,stddev_left=11.175209964478636\n",
    "# mu_middle=42.0 ,stddev_middle=2.8284271247461903 \n",
    "# ,mu_right=60.0,stddev_right=13.490737563232042  \n",
    "# left frame count = 37, transition prob = 0.08108108108108109, self = 0.9189189189189189\n",
    "# middle frame count = 3, transition prob = 1.0, self = 0.0\n",
    "# right frame count = 8, transition prob = 0.375, self = 0.625\n",
    "    \"\"\"Word NUTS\"\"\"\n",
    "\n",
    "    n_prior_probs = {\n",
    "        'N1': 0.333,\n",
    "        'N2': 0.,\n",
    "        'N3': 0.,\n",
    "        'Nend': 0.\n",
    "    }\n",
    "    # Probability of a state changing to another state.Íó „‚Íï¸Íó „ŒÍó „Íï¸†Íï¸‹Íó „\n",
    "    n_transition_probs = {\n",
    "        'N1': {'N3': 0., 'N1': 0.919, 'N2': 0.081, 'Nend': 0.},\n",
    "        'N2': {'N3': 1.0, 'N1': 0., 'N2': 0., 'Nend': 0.},\n",
    "        'N3': {'N3': 0.375, 'N2': 0., 'N1': 0., 'Nend': 0.625},\n",
    "        'Nend': {'N1': 0., 'N2': 0., 'N3': 0., 'Nend': 1.0}\n",
    "    }\n",
    "    # Parameters for end state is not requiredÍó „‚Íï¸Íó „ŒÍó „Íï¸†Íï¸‹Íó „\n",
    "    n_emission_paras = {\n",
    "        'N1': (38.081, 11.175),\n",
    "        'N2': (42.0, 2.828),\n",
    "        'N3': (60.0, 13.491),\n",
    "        'Nend': (None, None)\n",
    "    }\n",
    "\n",
    "# mu_left=29.5 ,stddev_left=8.411301920630361\n",
    "# mu_middle=36.18181818181818 ,stddev_middle=5.989660512737866 \n",
    "# ,mu_right=36.666666666666664,stddev_right=1.8856180831641267  \n",
    "# left frame count = 8, transition prob = 0.375, self = 0.625\n",
    "# middle frame count = 22, transition prob = 0.13636363636363635, self = 0.8636363636363636\n",
    "# right frame count = 3, transition prob = 1.0, self = 0.0\n",
    "    \"\"\"Word SLEEP\"\"\"\n",
    "    s_prior_probs = {\n",
    "        'S1': 0.333,\n",
    "        'S2': 0.,\n",
    "        'S3': 0.,\n",
    "        'Send': 0.\n",
    "    }\n",
    "    s_transition_probs = {\n",
    "        'S1': {'S1': 0.625, 'S3': 0., 'S2': 0.375, 'Send': 0.},\n",
    "        'S2': {'S1': 0., 'S2': 0.864, 'S3': 0.136, 'Send': 0.},\n",
    "        'S3': {'S1': 0., 'S3': 1., 'S2': 0., 'Send': 0.},\n",
    "        'Send': {'S3': 0.0, 'S2': 0., 'S1': 0., 'Send': 1.}\n",
    "    }\n",
    "    # Parameters for end state is not requiredÍó „‚Íï¸Íó „ŒÍó „Íï¸†Íï¸‹Íó „\n",
    "    s_emission_paras = {\n",
    "        'S1': (29.5, 8.411),\n",
    "        'S2': (36.182, 5.990),\n",
    "        'S3': (36.667, 1.886),\n",
    "        'Send': (None, None)\n",
    "    }\n",
    "\n",
    "    return (a_prior_probs, a_transition_probs, a_emission_paras,\n",
    "            n_prior_probs, n_transition_probs, n_emission_paras,\n",
    "            s_prior_probs, s_transition_probs, s_emission_paras)\n",
    "\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################Íó „‚Íï¸Íó „ŒÍó „Íï¸†Íï¸‹Íó „\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######Íó „‚Íï¸Íó „ŒÍó „Íï¸†Íï¸‹Íó „\n",
    "tests.TestPart1a().test_prior(part_1_a)\n",
    "tests.TestPart1a().test_a_emission(part_1_a)\n",
    "tests.TestPart1a().test_a_transition(part_1_a)\n",
    "tests.TestPart1a().test_n_emission(part_1_a)\n",
    "tests.TestPart1a().test_n_transition(part_1_a)\n",
    "\n",
    "tests.TestPart1a().test_s_emission(part_1_a)\n",
    "tests.TestPart1a().test_s_transition(part_1_a)\n",
    "################ END OF LOCAL TEST CODE SECTION ######################Íó „‚Íï¸Íó „ŒÍó „Íï¸†Íï¸‹Íó „"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1cfc2d",
   "metadata": {},
   "source": [
    "### Part 1b: Creating the Viterbi Trellis\n",
    "### _[CS6601: 40 Points]_ _[CS3600: 75 Points]_\n",
    "\n",
    "The goal here will be to use the HMM derived from Part 1a (states, prior probabilities, transition probabilities, and parameters of emission distribution) to build a viterbi trellis.  When provided with an evidence vector (list of observed right-hand Y coordinates), the function will return the most likely sequence of states that generated the evidence and the probabilty of that sequence being correct.\n",
    "\n",
    "For example, an evidence vector [38, 37, 35, 32, 35, 13, 36, 41, 41, 31, 32, 34, 34] (last training sequence for \"SLEEP\") should output a sequence ['S1', ... 'S2', ... 'S3']\n",
    "\n",
    "If no sequence can be found, the algorithm should return one of the following tuples:\n",
    "`(None, 0)` (null),  `([], 0)` (empty list) or  `(['A1', 'A1', ... 'A1'],0)` (Or all being the first state of that letter)\n",
    "\n",
    "\"No sequence can be found\" means the probability reaches 0 midway. If you find an incomplete sequence with some probability, output that sequence with its probability. \n",
    "\n",
    "Note: **DO NOT** consult any external sources other than the Wikipedia PDF in the assignment. Failure to abide by this requirement will lead to a 0 on the assignment.\n",
    "\n",
    "#### Functions to complete:\n",
    "1. `viterbi()`\n",
    "\n",
    "#### Hint:\n",
    "In order to reconstruct your most-likely path after running Viterbi, you'll need to keep track of a back-pointer at each state, which directs you to that state's most-likely predecessor.\n",
    "\n",
    "You are asked to use the provided function `gaussian_prob` to compute  emission probabilities. Although in real work, you have to convert the probability to log-base in order to prevent digit underflow, in this assignment, we will only test your function against a rather short sequence of observations, so **DO NOT** convert the probability to logarithmic probability, otherwise you will fail the tests on Gradescope.\n",
    "\n",
    "In the autograder, we will also test your code against other `evidence_vectors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f80023",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def gaussian_prob(x, para_tuple):\n",
    "    \"\"\"Compute the probability of a given x value\n",
    "\n",
    "    Args:\n",
    "        x (float): observation value\n",
    "        para_tuple (tuple): contains two elements, (mean, standard deviation)\n",
    "\n",
    "    Return:\n",
    "        Probability of seeing a value \"x\" in a Gaussian distribution.\n",
    "\n",
    "    Note:\n",
    "        We simplify the problem so you don't have to take care of integrals.\n",
    "        Theoretically speaking, the returned value is not a probability of x,\n",
    "        since the probability of any single value x from a continuous \n",
    "        distribution should be zero, instead of the number outputted here.\n",
    "        By definition, the Gaussian percentile of a given value \"x\"\n",
    "        is computed based on the \"area\" under the curve, from left-most to x. \n",
    "        The probability of getting value \"x\" is zero because a single value \"x\"\n",
    "        has zero width, however, the probability of a range of value can be\n",
    "        computed, for say, from \"x - 0.1\" to \"x + 0.1\".\n",
    "\n",
    "    \"\"\"\n",
    "    if list(para_tuple) == [None, None]:\n",
    "        return 0.0\n",
    "\n",
    "    mean, std = para_tuple\n",
    "    gaussian_percentile = (2 * np.pi * std**2)**-0.5 * \\\n",
    "                          np.exp(-(x - mean)**2 / (2 * std**2))\n",
    "    return gaussian_percentile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b2783a1f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evidence_vector=[20, 65, 20, 30, 45, 60, 60, 42] \n",
      "states=['A1', 'A2', 'A3', 'Aend', 'N1', 'N2', 'N3', 'Nend', 'S1', 'S2', 'S3', 'Send']\n",
      "prior_probs={'A1': 0.333, 'A2': 0.0, 'A3': 0.0, 'Aend': 0.0, 'N1': 0.333, 'N2': 0.0, 'N3': 0.0, 'Nend': 0.0, 'S1': 0.333, 'S2': 0.0, 'S3': 0.0, 'Send': 0.0}\n",
      "transition_probs={'A1': {'A2': 0.167, 'A3': 0.0, 'A1': 0.833, 'Aend': 0.0}, 'A2': {'A1': 0.0, 'A2': 0.786, 'A3': 0.214, 'Aend': 0.0}, 'A3': {'A2': 0.0, 'A1': 0.0, 'A3': 0.727, 'Aend': 0.273}, 'Aend': {'A2': 0.0, 'A3': 0.0, 'A1': 0.0, 'Aend': 1}, 'N1': {'N3': 0.0, 'N1': 0.919, 'N2': 0.081, 'Nend': 0.0}, 'N2': {'N3': 1.0, 'N1': 0.0, 'N2': 0.0, 'Nend': 0.0}, 'N3': {'N3': 0.375, 'N2': 0.0, 'N1': 0.0, 'Nend': 0.625}, 'Nend': {'N1': 0.0, 'N2': 0.0, 'N3': 0.0, 'Nend': 1.0}, 'S1': {'S1': 0.625, 'S3': 0.0, 'S2': 0.375, 'Send': 0.0}, 'S2': {'S1': 0.0, 'S2': 0.864, 'S3': 0.136, 'Send': 0.0}, 'S3': {'S1': 0.0, 'S3': 1.0, 'S2': 0.0, 'Send': 0.0}, 'Send': {'S3': 0.0, 'S2': 0.0, 'S1': 0.0, 'Send': 1.0}}\n",
      "emission_paras={'A1': (51.056, 21.986), 'A2': (28.357, 14.936), 'A3': (53.727, 16.707), 'Aend': (None, None), 'N1': (38.081, 11.175), 'N2': (42.0, 2.828), 'N3': (60.0, 13.491), 'Nend': (None, None), 'S1': (29.5, 8.411), 'S2': (36.182, 5.99), 'S3': (36.667, 1.886), 'Send': (None, None)}\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 51\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sequence, probability    \n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################Íó „‚Íï¸Íó „ŒÍó „Íï¸†Íï¸‹Íó „\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######Íó „‚Íï¸Íó „ŒÍó „Íï¸†Íï¸‹Íó „\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# tests.TestPart1b().test_viterbi_case1(part_1_a, viterbi)\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# tests.TestPart1b().test_viterbi_case2(part_1_a, viterbi)\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# tests.TestPart1b().test_viterbi_case3(part_1_a, viterbi)\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[43mtests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTestPart1b\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_viterbi_realsample1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpart_1_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mviterbi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# tests.TestPart1b().test_viterbi_realsample2(part_1_a, viterbi)\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# tests.TestPart1b().test_viterbi_realsample3(part_1_a, viterbi)\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m################ END OF LOCAL TEST CODE SECTION ######################Íó „‚Íï¸Íó „ŒÍó „Íï¸†Íï¸‹Íó „\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/CS6601_ex6/hmm_submission_test.py:233\u001b[0m, in \u001b[0;36mTestPart1b.test_viterbi_realsample1\u001b[0;34m(self, part_1_a, viterbi)\u001b[0m\n\u001b[1;32m    231\u001b[0m seq_ans \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA1\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    232\u001b[0m states, prior, trans, emiss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup(part_1_a)\n\u001b[0;32m--> 233\u001b[0m seq, prob \u001b[38;5;241m=\u001b[39m \u001b[43mviterbi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevidence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memiss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massertAlmostEqual(prob_ans, prob, places\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m21\u001b[39m)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# print(seq)Íó „‚Íï¸Íó „ŒÍó „Íï¸†Íï¸‹Íó „\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[33], line 42\u001b[0m, in \u001b[0;36mviterbi\u001b[0;34m(evidence_vector, states, prior_probs, transition_probs, emission_paras)\u001b[0m\n\u001b[1;32m     40\u001b[0m     sequence \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mS1\u001b[39m\u001b[38;5;124m\"\u001b[39m])[np\u001b[38;5;241m.\u001b[39margmax(mymatrix)]]\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sequence, probability\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m()\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sequence, probability\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#export\n",
    "def viterbi(evidence_vector, states, prior_probs,\n",
    "            transition_probs, emission_paras):\n",
    "    \"\"\"Viterbi Algorithm to calculate the most likely states give the evidence.\n",
    "    Args:\n",
    "        evidence_vector (list): List of right hand Y-axis positions (integer).\n",
    "        states (list): List of all states in a word. No transition between words.\n",
    "                       example: ['A1', 'A2', 'A3', 'Aend', 'N1', 'N2', 'N3', 'Nend']\n",
    "        prior_probs (dict): prior distribution for each state.\n",
    "                            example: {'X1': 0.25,\n",
    "                                      'X2': 0.25,\n",
    "                                      'X3': 0.25,\n",
    "                                      'Xend': 0.25}\n",
    "        transition_probs (dict): dictionary representing transitions from each\n",
    "                                 state to every other valid state such as for the above \n",
    "                                 states, there won't be a transition from 'A1' to 'N1'\n",
    "        emission_paras (dict): parameters of Gaussian distribution \n",
    "                                from each state.\n",
    "    Return:\n",
    "        tuple of\n",
    "        ( A list of states the most likely explains the evidence,\n",
    "          probability this state sequence fits the evidence as a float )\n",
    "    Note:\n",
    "        You are required to use the function gaussian_prob to compute the\n",
    "        emission probabilities.\n",
    "    \"\"\"\n",
    "    print (f\"evidence_vector={evidence_vector} \\nstates={states}\\nprior_probs={prior_probs}\\ntransition_probs={transition_probs}\\nemission_paras={emission_paras}\")\n",
    "    \n",
    "    # TODO: complete this function.Íó „‚Íï¸Íó „ŒÍó „Íï¸†Íï¸‹Íó „\n",
    "    if len(evidence_vector)==0:\n",
    "        sequence = []\n",
    "        probability = 0.0\n",
    "        return sequence, probability\n",
    "\n",
    "    if len(evidence_vector)==1:\n",
    "        mymatrix = np.array([prior_probs[\"A1\"] * gaussian_prob(evidence_vector[0], emission_paras[\"A1\"]),\n",
    "                             prior_probs[\"N1\"] * gaussian_prob(evidence_vector[0], emission_paras[\"N1\"]),\n",
    "                             prior_probs[\"S1\"] * gaussian_prob(evidence_vector[0], emission_paras[\"S1\"])])\n",
    "        probability = np.max(mymatrix)\n",
    "        sequence = [np.array([\"A1\",\"N1\",\"S1\"])[np.argmax(mymatrix)]]\n",
    "        return sequence, probability\n",
    "    \n",
    "    \n",
    "    raise NotImplementedError()\n",
    "    return sequence, probability    \n",
    "\n",
    "\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################Íó „‚Íï¸Íó „ŒÍó „Íï¸†Íï¸‹Íó „\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######Íó „‚Íï¸Íó „ŒÍó „Íï¸†Íï¸‹Íó „\n",
    "# tests.TestPart1b().test_viterbi_case1(part_1_a, viterbi)\n",
    "# tests.TestPart1b().test_viterbi_case2(part_1_a, viterbi)\n",
    "# tests.TestPart1b().test_viterbi_case3(part_1_a, viterbi)\n",
    "tests.TestPart1b().test_viterbi_realsample1(part_1_a, viterbi)\n",
    "# tests.TestPart1b().test_viterbi_realsample2(part_1_a, viterbi)\n",
    "# tests.TestPart1b().test_viterbi_realsample3(part_1_a, viterbi)\n",
    "################ END OF LOCAL TEST CODE SECTION ######################Íó „‚Íï¸Íó „ŒÍó „Íï¸†Íï¸‹Íó „"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039e0b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#case 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bd7b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#case len ==1\n",
    "evidence_vector=[30] \n",
    "states=['A1', 'A2', 'A3', 'Aend', 'N1', 'N2', 'N3', 'Nend', 'S1', 'S2', 'S3', 'Send']\n",
    "prior_probs={'A1': 0.333, 'A2': 0.0, 'A3': 0.0, 'Aend': 0.0, \n",
    "             'N1': 0.333, 'N2': 0.0, 'N3': 0.0, 'Nend': 0.0, \n",
    "             'S1': 0.333, 'S2': 0.0, 'S3': 0.0, 'Send': 0.0}\n",
    "\n",
    "transition_probs={'A1': {'A2': 0.167, 'A3': 0.0, 'A1': 0.833, 'Aend': 0.0}, \n",
    "                  'A2': {'A1': 0.0, 'A2': 0.786, 'A3': 0.214, 'Aend': 0.0}, \n",
    "                  'A3': {'A2': 0.0, 'A1': 0.0, 'A3': 0.727, 'Aend': 0.273}, \n",
    "                  'Aend': {'A2': 0.0, 'A3': 0.0, 'A1': 0.0, 'Aend': 1}, \n",
    "\n",
    "                  'N1': {'N3': 0.0, 'N1': 0.919, 'N2': 0.081, 'Nend': 0.0}, \n",
    "                  'N2': {'N3': 1.0, 'N1': 0.0, 'N2': 0.0, 'Nend': 0.0}, \n",
    "                  'N3': {'N3': 0.375, 'N2': 0.0, 'N1': 0.0, 'Nend': 0.625}, \n",
    "                  'Nend': {'N1': 0.0, 'N2': 0.0, 'N3': 0.0, 'Nend': 1.0}, \n",
    "\n",
    "                  'S1': {'S1': 0.625, 'S3': 0.0, 'S2': 0.375, 'Send': 0.0}, \n",
    "                  'S2': {'S1': 0.0, 'S2': 0.864, 'S3': 0.136, 'Send': 0.0}, \n",
    "                  'S3': {'S1': 0.0, 'S3': 1.0, 'S2': 0.0, 'Send': 0.0}, \n",
    "                  'Send': {'S3': 0.0, 'S2': 0.0, 'S1': 0.0, 'Send': 1.0}}\n",
    "\n",
    "emission_paras={'A1': (51.056, 21.986), 'A2': (28.357, 14.936), 'A3': (53.727, 16.707), 'Aend': (None, None), \n",
    "                'N1': (38.081, 11.175), 'N2': (42.0, 2.828),    'N3': (60.0, 13.491),   'Nend': (None, None), \n",
    "                'S1': (29.5, 8.411),    'S2': (36.182, 5.99),   'S3': (36.667, 1.886),  'Send': (None, None)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c70e7f",
   "metadata": {},
   "source": [
    "### Part 2a: Multidimensional Output Probabilities\n",
    "### _[Required for CS6601: 6 Points]_ _[Extra Credit for CS3600: 3 Points]_\n",
    "\n",
    "In Part 1a, we used right-hand Y-axis coordinates as our sole feature, now we are going to use two features - the same right-hand Y-axis coordinates and the right-thumb Y-axis coordinates. Using observations from both the right hand and the right thumb as features can increase the accuracy of our model when dealing with more complex sentences.\n",
    "\n",
    "Here you are given the transition probabilities and the means & standard deviations for emission parameters of right-thumb Y-axis locations, following the same procedure conducted in Part 1a.\n",
    "\n",
    "<img src=\"part_2_a_probs_updated.png\" alt=\"2a_probs\">\n",
    "\n",
    "ALLIGATOR | State 1 | State 2 | State 3\n",
    "--- | --- | --- | --- \n",
    "Mean | 53.529 | 40.769 | 51.000\n",
    "Std | 17.493 | 6.104 | 12.316\n",
    "\n",
    "NUTS | State 1 | State 2 | State 3\n",
    "--- | --- | --- | --- \n",
    "Mean | 36.318 | 60.000 | 37.476\n",
    "Std | 7.376 | 15.829 | 8.245\n",
    "\n",
    "SLEEP | State 1 | State 2 | State 3\n",
    "--- | --- | --- | --- \n",
    "Mean | 35.357 | 31.462 | 38.333\n",
    "Std | 7.315 | 5.048 | 7.409\n",
    "\n",
    "#### Functions to complete:\n",
    "1. `part_2_a()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c302dae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def part_2_a():\n",
    "    \"\"\"Provide probabilities for the word HMMs outlined below.\n",
    "    Now, at each time frame you are given 2 observations (right hand Y\n",
    "    position & right thumb Y position). Use the result you derived in\n",
    "    part_1_a, accompany with the provided probability for right thumb, create\n",
    "    a tuple of (right-hand-y, right-thumb-y) to represent high-dimension transition & \n",
    "    emission probabilities.\n",
    "    \"\"\"\n",
    "\n",
    "     # TODO: complete this function.Íó „‚Íï¸Íó „ŒÍó „Íï¸†Íï¸‹Íó „\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    \"\"\"Word ALLIGATOR\"\"\"\n",
    "    a_prior_probs = {\n",
    "        'A1': 0.333,\n",
    "        'A2': 0.,\n",
    "        'A3': 0.,\n",
    "        'Aend': 0.\n",
    "    }\n",
    "    # example: {'A1': {'A1' : (right-hand Y, right-thumb Y), ... }Íó „‚Íï¸Íó „ŒÍó „Íï¸†Íï¸‹Íó „\n",
    "    a_transition_probs = {\n",
    "        'A1': {'A3': (0., 0.), 'A2': (0., 0.), 'A1': (0., 0.), 'Aend': (0., 0.)},\n",
    "        'A2': {'A1': (0., 0.), 'A3': (0., 0.), 'A2': (0., 0.), 'Aend': (0., 0.)},\n",
    "        'A3': {'A2': (0., 0.), 'A3': (0., 0.), 'A1': (0., 0.), 'Aend': (0., 0.)},\n",
    "        'Aend': {'A1': (0., 0.), 'A2': (0., 0.), 'A3': (0., 0.), 'Aend': (0., 0.)}\n",
    "    }\n",
    "    # example: {'A1': [(right-hand-mean, right-thumb-std), (right-hand--mean, right-thumb-std)] ...}Íó „‚Íï¸Íó „ŒÍó „Íï¸†Íï¸‹Íó „\n",
    "    a_emission_paras = {\n",
    "        'A1': [(None, None), (None, None)],\n",
    "        'A2': [(None, None), (None, None)],\n",
    "        'A3': [(None, None), (None, None)],\n",
    "        'Aend': [(None, None), (None, None)]\n",
    "    }\n",
    "\n",
    "    \"\"\"Word NUTS\"\"\"\n",
    "    n_prior_probs = {\n",
    "        'N1': 0.333,\n",
    "        'N2': 0.,\n",
    "        'N3': 0.,\n",
    "        'Nend': 0.\n",
    "    }\n",
    "    n_transition_probs = {\n",
    "        'N1': {'N2': (0., 0.), 'N1': (0., 0.), 'N3': (0., 0.), 'Nend': (0., 0.)},\n",
    "        'N2': {'N2': (0., 0.), 'N3': (0., 0.), 'N1': (0., 0.), 'Nend': (0., 0.)},\n",
    "        'N3': {'N3': (0., 0.), 'N1': (0., 0.), 'N2': (0., 0.), 'Nend': (0., 0.)},\n",
    "        'Nend': {'N3': (0., 0.), 'N1': (0., 0.), 'N2': (0., 0.), 'Nend': (0., 0.)}\n",
    "    }\n",
    "    n_emission_paras = {\n",
    "        'N1': [(None, None), (None, None)],\n",
    "        'N2': [(None, None), (None, None)],\n",
    "        'N3': [(None, None), (None, None)],\n",
    "        'Nend': [(None, None), (None, None)]\n",
    "    }\n",
    "\n",
    "    \"\"\"Word SLEEP\"\"\"\n",
    "    s_prior_probs = {\n",
    "        'S1': 0.333,\n",
    "        'S2': 0.,\n",
    "        'S3': 0.,\n",
    "        'Send': 0.\n",
    "    }\n",
    "    s_transition_probs = {\n",
    "        'S1': {'S3': (0., 0.), 'S2': (0., 0.), 'S1': (0., 0.), 'Send': (0., 0.)},\n",
    "        'S2': {'S1': (0., 0.), 'S2': (0., 0.), 'S3': (0., 0.), 'Send': (0., 0.)},\n",
    "        'S3': {'S1': (0., 0.), 'S3': (0., 0.), 'S2': (0., 0.), 'Send': (0., 0.)},\n",
    "        'Send': {'S1': (0., 0.), 'S2': (0., 0.), 'S3': (0., 0.), 'Send': (0., 0.)}\n",
    "    }\n",
    "    s_emission_paras = {\n",
    "        'S1': [(None, None), (None, None)],\n",
    "        'S2': [(None, None), (None, None)],\n",
    "        'S3': [(None, None), (None, None)],\n",
    "        'Send': [(None, None), (None, None)]\n",
    "    }\n",
    "    return (a_prior_probs, a_transition_probs, a_emission_paras,\n",
    "            n_prior_probs, n_transition_probs, n_emission_paras,\n",
    "            s_prior_probs, s_transition_probs, s_emission_paras)\n",
    "\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################Íó „‚Íï¸Íó „ŒÍó „Íï¸†Íï¸‹Íó „\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######Íó „‚Íï¸Íó „ŒÍó „Íï¸†Íï¸‹Íó „\n",
    "tests.TestPart2a().test_prior(part_2_a)\n",
    "tests.TestPart2a().test_a_emission(part_2_a)\n",
    "tests.TestPart2a().test_n_emission(part_2_a)\n",
    "tests.TestPart2a().test_s_emission(part_2_a)\n",
    "tests.TestPart2a().test_a_transition(part_2_a)\n",
    "tests.TestPart2a().test_n_transition(part_2_a)\n",
    "tests.TestPart2a().test_s_transition(part_2_a)\n",
    "################ END OF LOCAL TEST CODE SECTION ######################Íó „‚Íï¸Íó „ŒÍó „Íï¸†Íï¸‹Íó „"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fdf584",
   "metadata": {},
   "source": [
    "### Part 2b: Improving the Viterbi Trellis\n",
    "### _[Required for CS6601: 39 Points]_ _[Extra Credit for CS3600: 7 Points]_\n",
    "\n",
    "Modify the Viterbi Trellis function to allow multiple observed values (Y locations of the right hand and the right thumb) for a state. The return format should be identical to Part 1b.\n",
    "\n",
    "Note: **DO NOT** consult any external sources other than the Wikipedia PDF in the assignment. Failure to abide by this requirement will lead to a 0 on the assignment.\n",
    "\n",
    "#### Functions to complete:\n",
    "1. `multidimensional_viterbi()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba3be3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def multidimensional_viterbi(evidence_vector, states, prior_probs,\n",
    "                             transition_probs, emission_paras):\n",
    "    \"\"\"Decode the most likely word phrases generated by the evidence vector.\n",
    "    States, prior_probs, transition_probs, and emission_probs will now contain\n",
    "    all the words from part_2_a.\n",
    "    Evidence vector is a list of tuples where the first element of each tuple is the right \n",
    "    hand coordinate and the second element is the right thumb coordinate.\n",
    "    \"\"\"\n",
    "    print (f\"evidence_vector={evidence_vector} \\\n",
    "                states={states}\\\n",
    "                prior_probs={prior_probs}\\\n",
    "                transition_probs={transition_probs}\\\n",
    "                emission_paras={emission_paras}\")\n",
    "    # TODO: complete this function.Íó „‚Íï¸Íó „ŒÍó „Íï¸†Íï¸‹Íó „\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    sequence = []\n",
    "    probability = 0.0\n",
    "\n",
    "    return sequence, probability\n",
    "\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################Íó „‚Íï¸Íó „ŒÍó „Íï¸†Íï¸‹Íó „\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######Íó „‚Íï¸Íó „ŒÍó „Íï¸†Íï¸‹Íó „\n",
    "tests.TestPart2b().test_viterbi_case1(part_2_a, multidimensional_viterbi)\n",
    "tests.TestPart2b().test_viterbi_case2(part_2_a, multidimensional_viterbi)\n",
    "tests.TestPart2b().test_viterbi_case3(part_2_a, multidimensional_viterbi)\n",
    "tests.TestPart2b().test_viterbi_realsample1(part_2_a, multidimensional_viterbi)\n",
    "tests.TestPart2b().test_viterbi_realsample2(part_2_a, multidimensional_viterbi)\n",
    "tests.TestPart2b().test_viterbi_realsample3(part_2_a, multidimensional_viterbi)\n",
    "################ END OF LOCAL TEST CODE SECTION ######################Íó „‚Íï¸Íó „ŒÍó „Íï¸†Íï¸‹Íó „"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86283be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def return_your_name():\n",
    "    \"\"\"Return your name\n",
    "    \"\"\"\n",
    "    # TODO: finish thisÍó „‚Íï¸Íó „ŒÍó „Íï¸†Íï¸‹Íó „\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4c5870",
   "metadata": {},
   "source": [
    "**CONGRATULATIONS!**  You have just completed your final assignment for CS6601 Artificial Intelligence.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
